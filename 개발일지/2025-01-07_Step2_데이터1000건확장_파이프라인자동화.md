# 개발일지 — 2025-01-07

## 진행 내용: Step2 데이터 1000건 확장 및 전체 파이프라인 자동화

### 1. 목표

- ✅ 데이터를 **412건 → 1000건**으로 확장
- ✅ 목표 분배표에 따른 **source_type 균형 조정**
  - inquiry: 30%, review: 30%, faq: 20%, dataset: 10%, notice: 10%
- ✅ 전체 파이프라인(확장→품질체크→전처리→EDA→리포트)을 **한 번에 실행**하는 배치 스크립트 구현
- ✅ 재현성 강화 및 out/ 리포트 자동 갱신

---

## 2. 주요 작업

### 2.1 데이터 1000건 확장 스크립트 개발

**파일**: `scripts/step2_expand_to_1000.py`

**핵심 기능**:
- 목표 분배표 기준으로 현재 데이터 대비 **부족분 자동 계산**
- 부족한 source_type별로 데이터 생성 및 병합
- **다양성 증대 로직** 적용:
  - 구어체 변형 (예: "어떻게" → "어케", "가능한가요" → "될까요")
  - 가벼운 오타 (예: "예약" → "예악", 15% 확률)
  - 공백/구두점 변형
  - 감정 표현 추가 (텍스트 기반: "ㅠㅠ", "...", "!!")
- **기존 스키마와 완전 일치**하는 컬럼 구조 생성
  - `text_id`, `text`, `created_at`, `sentiment_label`, `topic_label` 등 모든 필수/선택 컬럼 포함
  - 룰 기반 자동 라벨링 적용

**실행 결과**:
```
현재 데이터: 412건
목표 데이터: 1000건
추가 필요: inquiry +197, review +197, faq +89, dataset +49, notice +56
총 추가 필요: 588건
생성된 추가 데이터: 588건
최종 분포: inquiry 300, review 300, faq 200, dataset 100, notice 100
```

**산출물**:
- `data/step2_raw_text_expanded.csv` (1000건)
- `data/step2_expanded_added.csv` (추가된 588건만)
- `out/step2_expansion_to_1000_comparison.json` (전/후 비교)

---

### 2.2 전체 파이프라인 자동 실행 스크립트

**파일**: `scripts/run_full_pipeline.py`, `run_pipeline.bat`, `run_pipeline.sh`

**파이프라인 단계**:
1. **데이터 확장** (optional, `--skip_expansion`으로 건너뛰기 가능)
   - `step2_expand_to_1000.py` 실행
   - 목표 건수(기본 1000)에 맞춰 데이터 확장
2. **품질 체크**
   - `step2_quality_check.py` 실행
   - 필수 컬럼 결측, 중복(원문/dedup_key), PII, 라벨 품질 검사
3. **전처리**
   - `step2_preprocess_text.py` 실행
   - 결측 제거, 텍스트 정규화, PII 마스킹, 토큰화, 중복 제거
4. **EDA**
   - `step2_eda_text.py` 실행
   - 텍스트 길이 분포, 키워드 빈도, 라벨 분포 시각화
5. **EDA 리포트 생성**
   - `step2_generate_eda_report.py` 실행
   - 모든 분석 결과를 통합한 Markdown 리포트 자동 생성

**사용법**:
```powershell
# Windows 배치 파일로 실행
.\run_pipeline.bat

# Python 스크립트로 직접 실행
python .\scripts\run_full_pipeline.py --target 1000

# 데이터 확장 건너뛰기 (이미 확장 완료된 경우)
python .\scripts\run_full_pipeline.py --skip_expansion
```

**개선 사항**:
- Windows PowerShell 인코딩 문제 해결 (이모지 제거, cp949 호환)
- 각 단계별 실행 상태 표시 (`[Step]`, `[OK]`)
- 에러 발생 시 자동 중단 및 에러 코드 반환
- 최종 산출물 목록 자동 출력

---

### 2.3 EDA 리포트 개선

**파일**: `scripts/step2_generate_eda_report.py` 업데이트

**추가 섹션**:
- **"4) 데이터 1000건 확장 요약"**
  - 목표 총 건수, 목표 분배율
  - 확장 전/후 건수
  - source_type별 전/후 비교 테이블 (증가량 표시)
  
**리포트 예시** (`out/step2_eda_report.md`):
```markdown
## 4) 데이터 1000건 확장 요약

- **목표 총 건수**: 1000건
- **목표 분배율**: inquiry=30%, review=30%, faq=20%, dataset=10%, notice=10%
- **확장 전**: 412건
- **확장 후**: 1000건
- **추가 생성**: 588건

### source_type 분포 비교 (412건 → 1000건)

| source_type | 확장 전 | 확장 후 | 증가 |
|---|---:|---:|---:|
| dataset | 51 | 100 | +49 |
| faq | 111 | 200 | +89 |
| inquiry | 103 | 300 | +197 |
| notice | 44 | 100 | +56 |
| review | 103 | 300 | +197 |
```

---

## 3. 최종 산출물 (out/)

### 3.1 품질 체크 리포트
- `step2_quality_report.md`, `step2_quality_report.json`
- **Raw rows**: 1000건
- **필수 컬럼 결측 행**: 0 (✅ 스키마 불일치 문제 해결)
- **원문 중복 후보**: 513건
- **dedup_key 중복 후보**: 429건
- **PII**: 0/0/0 (URL/EMAIL/PHONE)
- **sentiment_label 결측률**: 26.8% (268/1000)
- **topic_label 결측률**: 26.8% (268/1000)

### 3.2 전처리 요약
- `step2_preprocess_summary.json`, `step2_preprocessed.csv`
- **before rows**: 1000
- **after rows**: 567 (중복 제거 후)
- **dedup_removed**: 421건
- **평균 토큰 수**: 5.2

### 3.3 EDA 시각화
- `eda_length_hist.png` (텍스트 길이 분포)
- `eda_sentiment_distribution.png` (감정 라벨 분포)
- `eda_topic_distribution.png` (주제 라벨 분포)
- `eda_top_keywords.csv` (빈도 키워드 Top 10)

**Top 10 키워드**:
1. 예약 (85회)
2. 검진 (68회)
3. 가능합니다 (45회)
4. 진료 (34회)
5. 가능한가요 (34회)

### 3.4 통합 리포트
- `step2_eda_report.md` (품질 요약 + 전처리 요약 + EDA + 확장 비교)

### 3.5 데이터 확장 비교
- `step2_expansion_to_1000_comparison.json`

---

## 4. 문제 해결

### 4.1 스키마 불일치 문제
**증상**: 확장된 데이터에서 588건이 `text` 컬럼 결측으로 표시됨

**원인**: 
- 초기 `step2_expand_to_1000.py`가 `raw_text`, `dedup_key`, `collected_at` 컬럼만 생성
- 기존 데이터의 `text_id`, `text`, `created_at` 등과 병합 시 불일치 발생

**해결**:
- `generate_row()` 함수를 수정해 **기존 스키마의 모든 컬럼을 포함**하도록 개선
- `text_id`, `text`, `created_at`, `rating`, `sentiment_label`, `topic_label`, `__source_file`, `source_url`, `raw_text`, `dedup_key`, `collected_at` 모두 생성
- 백업된 412건 데이터(`step2_raw_text_sample_412_backup.csv`)를 정제한 후 재확장

### 4.2 Windows PowerShell 인코딩 문제
**증상**: 이모지(`✅`, `🎉`) 출력 시 `UnicodeEncodeError: 'cp949' codec can't encode character`

**해결**:
- `run_full_pipeline.py`에서 이모지를 일반 텍스트로 변경
- `✅` → `[OK]`, `❌` → `[ERROR]`, `🎉` → `[완료]`, `📊` → `[산출물]`

---

## 5. 다음 단계 제안

### 5.1 라벨 품질 개선 (현재 결측률 26.8%)
- **자동 라벨링 보강**: 현재 룰 기반 자동 라벨링을 더 정교하게 개선
- **수동 검증**: `data/step2_raw_text_autolabeled.csv`에서 랜덤 50개 샘플링해 오분류 규칙 조정
- **라벨링 가이드 준수**: `라벨링가이드_v1.md` 기준으로 일관성 유지

### 5.2 데이터 다양성 추가 확대
- 현재 템플릿 기반 생성의 한계:
  - 중복률이 높음 (1000건 중 513건이 원문 중복 후보)
  - 전처리 후 567건으로 감소 (43% 손실)
- **해결 방안**:
  - 외부 데이터 수집 강화 (AI Hub, 공개 리뷰 데이터)
  - 템플릿 조합/변형 로직 고도화
  - 크롤링 범위 확대 (실제 병원/약국/검진센터 FAQ/리뷰)

### 5.3 모델 학습 준비
- 567건은 모델 학습/검증용으로는 부족
- **최소 1500~2000건 이상** 확보 권장
- 학습/검증/테스트 세트 분리 (7:2:1)

---

## 6. 참고 자료

- **목표 분배표 정의**: `scripts/step2_expand_to_1000.py` L16-L24
- **전체 파이프라인 실행**: `README.md` 섹션 5.2
- **라벨링 가이드**: `라벨링가이드_v1.md`
- **전처리 규정**: `전처리규정_v1.md`

---

## 7. 커밋 메시지 (제안)

```
feat: 데이터 1000건 확장 및 전체 파이프라인 자동화

- scripts/step2_expand_to_1000.py: 목표 분배표 기준 데이터 확장 (412→1000건)
- scripts/run_full_pipeline.py: 전체 파이프라인 자동 실행 스크립트
- run_pipeline.bat, run_pipeline.sh: 배치 파일 추가 (Windows/Unix)
- scripts/step2_generate_eda_report.py: 1000건 확장 요약 섹션 추가
- README.md: 전체 파이프라인 실행 가이드 추가

[데이터 품질]
- Raw 1000건 (결측 0), 전처리 후 567건
- source_type 균형 조정: inquiry 30%, review 30%, faq 20%, dataset 10%, notice 10%
- 다양성 증대: 구어체, 오타, 공백 변형, 감정 표현 추가

[재현성]
- 한 명령으로 전체 파이프라인 실행 가능
- 단계별 산출물 자동 갱신 (out/)
```


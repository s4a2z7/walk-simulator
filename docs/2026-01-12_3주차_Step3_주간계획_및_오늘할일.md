# 2026-01-12 (월) — 3주차 Step 3(모델 개발/프롬프트 엔지니어링) 주간 계획 + 오늘 할 일

## 이번 주 목표(3주차)
- **기본 프롬프트 설계**: 기능별 프롬프트 초안(리뷰 요약/대화 요약/키워드 추출) 확정
- **프롬프트 반복 개선**: 평가 기준에 따라 2~3회 반복 개선 + 변경 로그 남기기
- **기능 통합 및 자동화 실습**: 샘플 입력 → 출력(요약/키워드)까지 **스크립트 1개로 재현**

---

## 요일별 계획(월~금)
| 요일 | 핵심 작업 | 산출물 | 완료 기준 |
|---|---|---|---|
| 월(오늘) | 기본 프롬프트 설계 + 소량 샘플 테스트 + 평가 기준 확정 | 프롬프트 초안 + 테스트 결과 샘플 + 평가 루브릭 | 기능 3개 모두 “입력/출력 형식”이 고정되고 샘플 결과 3~5개 확보 |
| 화 | 1차 반복 개선(실패 케이스 중심) | v1 프롬프트 + 변경 로그 | 품질/형식 오류 감소(루브릭 기준 개선) |
| 수 | 2차 반복 개선 + 예외 케이스(길이/노이즈/라벨 결측) 대응 | v2 프롬프트 + 실패 케이스 목록 | “왜 실패했는지”와 수정 근거가 문서화 |
| 목 | 기능 통합/자동화(스크립트/파이프라인 연결) | 실행 스크립트 + 출력 파일(out/) | 한 번 실행으로 결과 재현 가능 |
| 금 | 데모 시나리오 점검 + 문서 업데이트 | 데모 시나리오/설명서 | 타인이 따라해도 재현 가능 |

---

## 오늘 해야 하는 일(월)

### 🎯 기본 프롬프트 설계하기
1) **기능별 프롬프트 초안 작성**
   - 리뷰 요약
   - 대화 요약(현재 데이터가 단문 중심이므로, “여러 발화 묶음” 입력 포맷도 함께 정의)
   - 키워드 추출

2) **작은 샘플 데이터로 프롬프트 테스트**
   - 입력: `out/step2_preprocessed.csv` 중 일부(예: 10~20개)
   - 결과 샘플을 `out/step3_prompt_test_samples.md`로 저장

3) **결과 평가 기준 설정**
   - 정확도(핵심 정보 보존)
   - 간결성(불필요한 문장/중복 감소)
   - 일관성(형식/톤/정책 준수)
   - 안전성/환각(없는 내용 생성 금지)

### 오늘 산출물(체크)
- [x] **프롬프트 초안**(파일로 저장)
- [x] **테스트 결과 샘플**(파일로 저장)
- [x] **평가 기준(루브릭)**(파일로 저장)
- [x] **스코어 시트(평가표) 작성**(최소 3~5개 샘플 채점) → `docs/step3_prompt_score_sheet.md`에 기록

---

## 오늘 문서/파일 작업 범위(포함/제외)
- **포함**
  - Step3 기능 3종 프롬프트 초안 “고정”(입력/출력 형식, JSON 스키마, 톤)
  - 소량 샘플 테스트(3~5개 이상) + 결과 샘플 저장
  - 평가 기준(루브릭) 확정 + 스코어 시트(평가표)로 채점 기록 시작
- **제외(오늘은 안 함)**
  - 대규모 배치 테스트(수백~수천 건)
  - 모델 파인튜닝/학습
  - UI/프론트엔드 연동(필요 시 목/금에)

---

## 저장 위치(오늘 산출물 경로)
- **프롬프트 초안**: `prompts/`
  - `prompts/step3_review_summary.md`
  - `prompts/step3_dialog_summary.md`
  - `prompts/step3_keyword_extraction.md`
  - `prompts/step3_text_classification.md` (분류)
- **평가 루브릭(기준)**: `docs/step3_prompt_evaluation_rubric.md`
- **스코어 시트(평가표 템플릿)**: `docs/step3_prompt_score_sheet.md`
- **테스트 결과 샘플(오늘 출력 붙여넣기)**: `out/step3_prompt_test_samples.md`
- **통합 파이프라인 결과(샘플)**:
  - `out/step3_pipeline_samples.md`
  - `out/step3_pipeline_results.jsonl`
- **(선택) 변경 로그**: `docs/step3_prompt_change_log.md` (없으면 생성)

---

## 실행 커맨드(로컬/Windows 기준)
> OPENAI_API_KEY가 없으면 자동으로 `dry-run` 모드로 실행되며, 프롬프트 렌더링/로그만 저장된다.

- **.env 준비**
  - `example.env`를 `.env`로 복사 후 `OPENAI_API_KEY`를 채운다(레포에 커밋 금지).
- **프롬프트 단일 테스트(샘플 5개)**
  - `py -3 scripts\\step3_prompt_test.py --n 5`
- **통합 파이프라인 스모크 테스트(샘플 8개 + 분류 포함)**
  - `py -3 scripts\\step3_prompt_pipeline.py --n 8 --enable_classification`

---

## 오늘 실행 결과(현황)
- 실행 결과: **결제 후 live 응답 생성 성공**
- 실행 로그/샘플 생성됨
  - `out/step3_prompt_test_samples.md`
  - `out/step3_prompt_test_results.jsonl`
  - `out/step3_pipeline_samples.md`
  - `out/step3_pipeline_results.jsonl`
- 평가/기록 문서
  - `docs/2026-01-12_Step3_live_run_summary.md` (오늘 실행/평가 보류 사유 포함)
  - `docs/step3_prompt_change_log.md` (오늘: 프롬프트 변경 없음/평가 기록)

## 🎯 프롬프트 반복 개선하기(오늘은 “1차 개선 준비”까지)
1) **모델 응답 비교 및 평가**
   - [ ] 동일 입력에 대해 프롬프트 2안(A/B) 또는 “수정 전/후” 비교
   - [ ] 루브릭 기준으로 점수 부여(최소 3개 샘플)

2) **프롬프트 수정 포인트 정리(체크리스트)**
   - [ ] **명령어 구체화**: 출력 길이/문장 수/bullet 수/금지 규칙을 더 명확히
   - [ ] **형식 강화**: “JSON만 반환”, “필드 누락 금지”, “배열 길이 제한” 명시
   - [ ] **예시 추가(필요 시)**: 1개만(과적합 방지). 예시는 입력-출력 둘 다 포함
   - [ ] **톤/스타일 조정**: 중립적, 과장 금지, 사실 기반 유지

3) **반복 테스트 및 성능 기록(오늘 최소 1회)**
   - [ ] 수정 후 재실행(동일 샘플) → 점수 변화 기록
   - [ ] 실패 케이스 1~2개 선정해 “원인/대응” 메모

### 산출물(반복 개선 파트)
- [ ] **개선된 프롬프트 세트(v1)** 또는 “개선 후보” 메모
- [ ] **성능 평가표(스코어 시트)**에 점수/코멘트 기록(최소 3개)

---

## 🎯 기능 통합 및 자동화 실습하기(오늘은 “설계/뼈대”까지 가능하면 착수)
1) **파이프라인 연결 설계**
   - 입력(텍스트/대화) → `review_summary`/`dialog_summary` → `keyword_extraction` → 결과 저장(out/)
   - [ ] 각 단계의 **입력 필드명/출력 JSON**을 “고정”하고 문서에 반영

2) **API 호출 자동화(스크립트 작성)**
   - [ ] 스크립트 파일 위치/이름 결정(예: `scripts/step3_prompt_pipeline.py`)
   - [ ] 환경변수(키/모델/엔드포인트) 주입 방식 확정(예: `.env`, `example.env` 참고)

3) **통합 테스트(간단 입력 데이터)**
   - [ ] 샘플 1~3개 입력으로 end-to-end 실행
   - [ ] 로그/출력을 `out/`에 저장(재현 가능하게)

### 산출물(통합/자동화 파트)
- [ ] **통합 기능 코드(스크립트 1개)** 초안 생성
- [ ] **테스트 로그/출력 파일** 저장(샘플 1~3개)

---

## 오늘 실행 순서(추천, 90~120분 기준)
- [ ] (10분) 프롬프트 3종 초안 최종 확인(입력 변수: `{{text}}`, `{{dialog}}`)
- [ ] (30분) 샘플 3~5개로 테스트 실행 → `out/step3_prompt_test_samples.md`에 결과 붙여넣기
- [ ] (20분) 루브릭 기준으로 채점 → `docs/step3_prompt_score_sheet.md`에 기록
- [ ] (20분) 점수 낮은 항목 1~2개만 골라 프롬프트 1차 수정
- [ ] (10분) 동일 샘플로 재테스트 + 변화 기록
- [ ] (선택 30분) 파이프라인/스크립트 뼈대 착수(입출력 스키마 확정 우선)


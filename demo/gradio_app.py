#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step4 - Gradio ë°ëª¨ UI (ì±—ë´‡ ì „ìš© í™”ë©´)

ëª©í‘œ:
- â€œì¹´ì¹´ì˜¤í†¡ì²˜ëŸ¼â€ ì±—ë´‡ë§Œ ë³´ì´ëŠ” ë‹¨ì¼ í™”ë©´(íƒ­/ëª¨ë¸ ì„ íƒ UI ì œê±°)
- ì „ì†¡ ì‹œ Tabs ê´€ë ¨ ì—ëŸ¬ë¥¼ í”¼í•˜ê¸° ìœ„í•´ Tabsë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.

ì‹¤í–‰:
    python demo/gradio_app.py
"""

from __future__ import annotations

import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import gradio as gr
from dotenv import load_dotenv

try:
    from openai import OpenAI  # type: ignore
except Exception:  # pragma: no cover
    OpenAI = None  # type: ignore


ROOT = Path(__file__).resolve().parent.parent
PROMPTS_DIR = ROOT / "prompts"

P_CHATBOT = PROMPTS_DIR / "step4_chatbot.md"

def _read_text(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def _split_prompt(md: str) -> tuple[str, str]:
    if "## System" not in md or "## User" not in md:
        raise ValueError("prompt format must include '## System' and '## User'")
    sys_part = md.split("## System", 1)[1].split("## User", 1)[0].strip()
    user_part = md.split("## User", 1)[1].strip()
    return sys_part, user_part


@dataclass(frozen=True)
class Prompts:
    bot_sys: str


def load_prompts() -> Prompts:
    bot_sys, _ = _split_prompt(_read_text(P_CHATBOT))
    return Prompts(bot_sys)


def call_openai_messages(model: str, messages: list[dict[str, str]], temperature: float = 0.2) -> str:
    if OpenAI is None:
        raise RuntimeError("openai íŒ¨í‚¤ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. requirements.txt ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    client = OpenAI()
    resp = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
    )
    return (resp.choices[0].message.content or "").strip()

def chat_fn(message: str, history: list[tuple[str, str]]) -> tuple[str, list[tuple[str, str]]]:
    """
    ìˆ˜ë™ ì±—ë´‡: (answer, updated_history) ë°˜í™˜.
    """
    load_dotenv(ROOT / ".env")
    api_key = os.getenv("OPENAI_API_KEY", "").strip()
    if not api_key:
        answer = "âš ï¸ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤(.env ì„¤ì • í•„ìš”)."
        history.append((message, answer))
        return "", history

    prompts = load_prompts()
    user_msg = (message or "").strip()
    if not user_msg:
        return "", history

    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ êµ¬ì„±
    msgs: list[dict[str, str]] = [{"role": "system", "content": prompts.bot_sys}]
    for u, a in (history or []):
        if u:
            msgs.append({"role": "user", "content": str(u)})
        if a:
            msgs.append({"role": "assistant", "content": str(a)})
    msgs.append({"role": "user", "content": user_msg})

    try:
        bot_reply = call_openai_messages(model=model, messages=msgs, temperature=0.4)
    except Exception as e:
        bot_reply = f"âš ï¸ (ì˜¤ë¥˜) {type(e).__name__}: {e}"

    history.append((user_msg, bot_reply))
    return "", history


def main() -> None:
    css = """
    /* ì¹´ì¹´ì˜¤í†¡ ëŠë‚Œ: ì¤‘ì•™ ì •ë ¬ + ë„“ì´ ì œí•œ */
    .gradio-container { max-width: 720px !important; margin: 0 auto !important; }
    """
    with gr.Blocks(title="CareLog ì±—ë´‡", css=css) as demo:
        gr.Markdown("## ğŸ¥ CareLog ì±—ë´‡")
        gr.Markdown("ì˜ˆì•½/ì•ˆë‚´ ì¤‘ì‹¬ ì˜ë£Œ ì„œë¹„ìŠ¤ ì±—ë´‡ (ê±´ê°•ê²€ì§„/ë³‘ì›/ì•½êµ­)")

        chatbot = gr.Chatbot(label="ëŒ€í™”", height=500)
        msg = gr.Textbox(
            label="ë©”ì‹œì§€",
            placeholder="ì˜ˆ: ì˜¤ëŠ˜ ê±´ê°•ê²€ì§„ ì˜ˆì•½ ê°€ëŠ¥í•œê°€ìš”?",
            show_label=False,
        )

        with gr.Row():
            submit = gr.Button("ì „ì†¡", variant="primary")
            clear = gr.Button("ëŒ€í™” ì´ˆê¸°í™”")

        gr.Examples(
            examples=[
                "ì˜¤ëŠ˜ ê±´ê°•ê²€ì§„ ì˜ˆì•½ ê°€ëŠ¥í•œê°€ìš”?",
                "ì˜ˆì•½ ë³€ê²½ì€ ì–¸ì œê¹Œì§€ ê°€ëŠ¥í•œê°€ìš”?",
                "ì˜ì—…ì‹œê°„ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            ],
            inputs=msg,
        )

        # ì „ì†¡ ì´ë²¤íŠ¸ ì—°ê²°
        msg.submit(chat_fn, [msg, chatbot], [msg, chatbot])
        submit.click(chat_fn, [msg, chatbot], [msg, chatbot])
        clear.click(lambda: ([], ""), outputs=[chatbot, msg])

    demo.launch(show_api=False, share=True, server_name="0.0.0.0")


if __name__ == "__main__":
    main()


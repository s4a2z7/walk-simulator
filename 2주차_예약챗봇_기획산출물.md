# 2주차 예약 챗봇 기획 산출물

## 1. 프로젝트 목표 요약 (3~4줄)
Step2는 외부 데이터셋 구축을 목표로 하며, 한국어 의료 대화 데이터를 수집·전처리하여 LLM 학습 및 검색용으로 활용하는 것을 목적으로 함. 초기 350건 규모로 중복 제거, EDA, 라벨링 가이드라인 수립을 완료하였음. 궁극적으로 1000건 확장과 품질 검증을 통해 의료 챗봇 개발에 기여함.

## 2. 현재 데이터셋 상태 요약 (숫자 중심)
- (기준선 v1) 원본 데이터: 1000건 (provider_type: HOSPITAL 375, CHECKUP_CENTER 317, PHARMACY 308; source_type: review 300, inquiry 300, faq 200, dataset 100, notice 100).
- (기준선 v1) 전처리 후: 570건 (dedup 제거 420건, 평균 토큰 5.19, 길이 8-50).
- (라벨 품질) 원본 라벨 결측: sentiment/topic 각각 26.8% (268/1000) → (선택) 룰 기반 임시 보완 적용 시 결측 0%로 보완 가능(보완 건수 268/268, 리포트에 명시).
- EDA 결과(최신): 상위 키워드 '예약' 89, '검진' 68; 감정/토픽 분포 시각화 및 통합 리포트 갱신 완료.

## 3. 주요 리스크와 대응 현황 (표)

| 리스크 | 현황 | 대응 | 상태 |
|--------|------|------|------|
| 중복 데이터 | (v1 Raw=1000) 원문 513건, dedup_key 427건 중복 후보 | 전처리 단계에서 dedup_key 기반 제거 적용 | 완료 (전처리 후 570건, dedup 제거 420건) |
| 문체 편중 | (v1) source_type: review 30%, inquiry 30%, faq 20%, dataset/notice 10% | 확장/생성 시 목표 분배율 유지 + EDA로 편중 모니터링 | 현재 적정, 주기 점검 |
| 도메인 편중 | MEDICAL/GENERAL 정의 필요 및 비율 관리 필요 | provider_type 기반 MEDICAL/GENERAL(70/30) 정렬(v2) + 별도 raw로 관리 | v2에서 700/300 달성 |
| 라벨 품질 | (v1) 라벨 결측 26.8% | 허용값 표준화 + 품질 체크 강화 + (선택) 룰 기반 임시 보완 | 임시 보완 시 결측 0%(보완 건수 리포트 명시) |

## 4. 현재 단계에서의 판단 (적정성 평가)
현재 단계(v1 기준)는 1000건 규모의 Raw 데이터에 대해 품질 체크/전처리/EDA가 재현 가능하게 고정되어 있어 프로토타이핑에 적합함. 라벨 결측이 일부 남아 있으나(26.8%), 임시 룰 기반 보완으로 결측 0%까지 내려 EDA/모델링 공백을 줄일 수 있음(단, 수동 검증 필요). 또한 MEDICAL/GENERAL 비율 관리는 v2에서 별도 raw로 분리하여 리스크 없이 실험 가능하도록 구조를 갖춤. 전체적으로 다음 단계(라벨 검증 + 비율 관리)로의 전환이 타당함.

## 5. 다음 단계 제안 (2~3가지 옵션)
1. 라벨링 완료 우선: 결측률 0% 달성 후 품질 검증 (교차 검토 10%, 일치율 90% 목표), 이후 모델 학습 테스트.
2. 데이터 확장 병행: 1000건 목표로 MEDICAL 700건, GENERAL 300건 수집, 합법성/품질 체크 적용.
3. 통합 검증 옵션: 확장 데이터와 기존 데이터 병합 후 EDA 재실행, 리스크 재평가 및 보고서 업데이트.

## 6. 리스크 관리 관점 요약 자료

| 리스크 | 발견 시점 | 대응 방식 | 현재 상태 | 남은 한계 |
|------|-----------|----------|-----------|-----------|
| 데이터 양 부족 | 수집 초기 (350건) | 1000건 확장 수행 + 파이프라인 자동화 | v1 Raw 1000건 확보, 전처리/EDA 재현 가능 | 질적 다양성(실데이터 비중) 보강 여지 |
| 도메인 편향 | 비율 관리 설계 단계 | MEDICAL/GENERAL 정의 + 70/30 정렬(v2 raw 분리) | v2 raw에서 700/300 달성 | 정의(무엇이 GENERAL인지) 팀 합의 필요 |
| 중복 데이터 | 품질 체크/전처리 단계 | dedup_key 기반 중복 제거 + 지표 모니터링 | v1 전처리 후 570건(제거 420건) | 의미적 유사(동의문) 잔존 가능 |
| 문체 편중 | EDA 단계 | source_type 분배율 유지(30/30/20/10/10) | 현재 적정(분포 가시화/리포트 포함) | 생성 데이터 과다 시 자연스러움 저하 가능 |
| 라벨 결측/불일치 | 품질 체크 단계 | 허용값 표준화 + 결측/위반/분포 TopN 검사 + (선택) 임시 보완 | 임시 보완 시 결측 0%(보완 건수 명시) | 자동 보완 라벨의 정확도 검증 필요 |

## 7. 우선순위 결정 논리 설명
우선순위 결정 논리는 품질 기반 접근입니다. 데이터의 기초가 튼튼해야 확장이 의미 있으므로, 중복 제거와 라벨 가이드를 먼저 처리했습니다. 중복 정합성은 데이터 일관성을 확보해 모델 학습 편향을 방지하고, 라벨 가이드는 분류 표준을 세워 이후 작업의 기준이 됩니다. 이 단계가 먼저여야 확장 시 효율적입니다.

잘못된 순서로 갔을 때의 리스크는 큽니다. 먼저 확장하면 중복이 늘어나 정리 비용이 급증하고, 라벨 없이 데이터를 늘리면 일관성 없는 라벨링으로 품질이 떨어져 전체 재작업이 필요할 수 있습니다. 이는 시간과 리소스 낭비로 이어집니다.

현재 선택의 장점은 명확합니다. 323건의 데이터가 이미 신뢰할 수 있는 상태로, 확장 시 기초로 활용 가능합니다. 라벨 가이드 덕분에 새로운 데이터도 일관되게 처리할 수 있어, 장기적으로 프로젝트 안정성이 높아집니다. 이 접근은 실무적 판단으로, 빠른 피드백 루프를 유지합니다.

## 8. 강사 피드백 요청 질문
- 데이터 확장 시 MEDICAL과 GENERAL의 비율을 어떻게 조정하는 게 프로젝트 목표에 더 적합할까?
- 라벨 결측률을 낮추기 위해 수동 검토와 자동 도구를 어느 정도로 결합하는 게 효율적일까?
- 문체 편중을 완화하기 위해 source_type 다양화를 어떤 전략으로 추진하는 게 좋을까?
- 중복 데이터 리스크를 넘어 의미적 유사성까지 고려한 추가 검증을 어느 단계에 도입하는 게 적절할까?
- 현재 EDA 결과를 바탕으로 다음 우선 작업을 예약 챗봇 적용과 일반 LLM 학습 중 어느 쪽으로 기울이는 게 타당할까?
- 리스크 관리 표를 확장하여 어떤 추가 항목을 포함하는 게 프로젝트 안정성에 도움이 될까?
- 라벨 가이드라인 v1을 실제 적용 시 예상되는 어려움을 어떻게 사전에 대비하는 게 좋을까?

## 9. PPT 한 장 요약
### Step2 데이터셋 프로젝트 요약

**프로젝트 한 줄 요약**  
의료 예약 챗봇용 한국어 대화 데이터셋 구축 (수집 → 전처리 → EDA 완료)

**현재 데이터 상태**  
- (v1) 총 Raw: 1000건 → 전처리 후: 570건 (dedup 제거 420건)  
- 평균 토큰: 5.19 (길이: 8-50)  
- provider_type: HOSPITAL 375, CHECKUP_CENTER 317, PHARMACY 308  
- source_type: review 300, inquiry 300, faq 200, dataset 100, notice 100  
- 라벨 결측: 26.8% (선택 임시 보완 시 0%)

**리스크 대응 요약**  
- 중복: dedup_key 기반 제거 (중복률 7.7%)  
- 편중: 도메인(MEDICAL 100%) / 문체(faq 32%) 확인, GENERAL 도입 계획  
- 품질: PII 마스킹, 라벨 가이드 v1 수립  
- 검증: EDA 완료, 품질 체크리스트 적용

**다음 단계**  
- 라벨링 완료 (결측 0% 목표)  
  - 1차: 룰 기반 임시 보완(자동) + 보완 플래그/건수 리포트 명시  
  - 2차: 샘플링 수동 검증(예: 10%) 후 룰/가이드 개선
- 데이터 확장/정렬 (1000건: MEDICAL 700, GENERAL 300)  
  - v1은 유지하고, v2용 raw(`data/step2_raw_text_expanded_mg_700_300.csv`)를 별도로 생성해 파이프라인/리포트를 분리 관리
- 통합 검증 및 보고서 업데이트 (v1/v2 비교 + 리스크 표 갱신)